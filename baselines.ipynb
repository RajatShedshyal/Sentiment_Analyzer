{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7123750-337d-4781-8d55-58fa662da037",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2d4a22e-2bef-45ed-ba26-23273f9b6e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b65b8d-3651-4083-9cb9-8f7b9154b063",
   "metadata": {},
   "source": [
    "## PreProcessing and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db48ead-4378-4045-a18f-ee6c3fbddaee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data original size: (2129, 2)\n",
      "data size after dropping null values: (2129, 2)\n",
      "data size after dropping duplicate values: (321, 2)\n"
     ]
    }
   ],
   "source": [
    "#PreProcessing and Cleaning\n",
    "import re # regular expression model for getting rid of patterns\n",
    "from sklearn.preprocessing import LabelEncoder # for label encoding\n",
    "\n",
    "#Import data\n",
    "data = pd.read_csv(\"reply_classification_dataset.csv\")\n",
    "print(f\"data original size: {data.shape}\")\n",
    "\n",
    "#Get rid of NULL values\n",
    "\n",
    "df = data.dropna()\n",
    "print(f\"data size after dropping null values: {data.shape}\")\n",
    "\n",
    "#Cleaning the texts\n",
    "def clean_text(text):\n",
    "\n",
    "    #Safe handling\n",
    "    if not isinstance(text, str):\n",
    "        return None\n",
    "\n",
    "    def remove_non_ascii(text):\n",
    "        return text.encode(\"ascii\", \"ignore\").decode()\n",
    "\n",
    "    text = remove_non_ascii(text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # collapse multiple spaces\n",
    "    text = text.strip() #removes unnecessary early and after spaces\n",
    "    return text.lower()\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(clean_text)\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"reply\", \"label\"], keep=\"last\")\n",
    "print(f\"data size after dropping duplicate values: {df.shape}\")\n",
    "\n",
    "#Encoding the differnt labels\n",
    "LE = LabelEncoder()\n",
    "df[\"encoded\"] = LE.fit_transform(df[\"label\"]) #values are assigned alphabetically, so neg->0, neutral->1, pos->2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2275809-e26d-44b3-b04e-b47c546320be",
   "metadata": {},
   "source": [
    "### Too many duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "111f531d-03c8-4142-84ce-f37b77a41b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reply</th>\n",
       "      <th>label</th>\n",
       "      <th>encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can we discuss pricing??</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im excited to explore this further, plz send c...</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we not looking for new solutions.</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>could u clarify features included?</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lets,, schedule a meeting to dive deeper</td>\n",
       "      <td>positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reply     label  encoded\n",
       "0                           can we discuss pricing??   neutral        1\n",
       "1  im excited to explore this further, plz send c...  positive        2\n",
       "2                  we not looking for new solutions.  negative        0\n",
       "3                 could u clarify features included?   neutral        1\n",
       "4           lets,, schedule a meeting to dive deeper  positive        2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714eb320-04f5-4ee0-8c87-95b71dc25da9",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7530a15e-289c-425e-998a-96a188bc3f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded\n",
      "1    121\n",
      "2    114\n",
      "0     86\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,5))  \n",
    "ax = df['encoded'].value_counts().plot(kind='bar', color='pink')\n",
    "ax.set_xlabel(\"Labels\")\n",
    "ax.set_ylabel(\"Counts\")\n",
    "print(df['encoded'].value_counts())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5aad99-70d9-42e0-b337-ed0712a38c20",
   "metadata": {},
   "source": [
    "### There is Class Imbalance here (will use stratified split for traing and testing, and class weights so that i penalize model harder for wrong clasification of a class whose frequency is lesss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9690a882-492e-4677-93b9-30deee811a45",
   "metadata": {},
   "source": [
    "## Train-Test-Split + Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d6176bd-7002-43e9-9809-9a7ce280a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e44d34e5-3d4e-4f25-ab9c-4ea15776911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[\"reply\"], df[\"encoded\"], test_size=test_size, random_state=42, stratify=df[\"encoded\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4fc1dce-8415-4650-b6ba-b9b887f3bdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1368       this could streamline, connect!\n",
       "1799                   not good fit for us\n",
       "1813            send pricing structure plz\n",
       "2120            not interested, thank you.\n",
       "3       could u clarify features included?\n",
       "Name: reply, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bcad631-14b9-4ba3-a03c-e1dfd85e2649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding the vectors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "scaler = StandardScaler(with_mean=False)  # TF-IDF is sparse\n",
    "X_train_vec = scaler.fit_transform(X_train_vec)\n",
    "X_test_vec = scaler.transform(X_test_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a56c84-fffd-4de5-a8dd-e28549d48ffd",
   "metadata": {},
   "source": [
    "#### Note, here spliting before Vectorizing is important or else this will lead to train-test-leakage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a27cb7-c43a-4fba-afbe-021a0e54e3ec",
   "metadata": {},
   "source": [
    "## Training a ML Model (Log Reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ee3aafd-a12b-4bec-8542-de28383112f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=500)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(class_weight=&#x27;balanced&#x27;, max_iter=500)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(class_weight='balanced', max_iter=500)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=500, class_weight=\"balanced\")\n",
    "lr_model.fit(X_train_vec, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11ee869d-1463-42b0-b7f2-a5dbfd49afb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9846153846153847\n",
      "F1 Score: 0.9846220648652259\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "y_pred = lr_model.predict(X_test_vec)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred, average=\"weighted\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6fc2562-3f6b-48a6-8e27-51775f6291b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "sample_text = [\"I am good boy\", \"i am not feeling well\", \" im looking forward to presentation!\", \"plz send feature roadmap\", \"we not looking for new solutions.\"]\n",
    "sample_tfidf = vectorizer.transform(sample_text)\n",
    "\n",
    "preds = lr_model.predict(sample_tfidf)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7789a2-63b5-482d-bb6a-c9217a1417d7",
   "metadata": {},
   "source": [
    "#### due to tf-idf having many features, and the data being very small we are getting a f1 score of 1. (PERFECT SCORE) usally it is not possible, that is if i put in an actual negative senetence that is entirely different from these reviews dataset we will get a incorrect prediciton"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e197a04-78b3-4618-9a74-7fc3c22bba87",
   "metadata": {},
   "source": [
    "## Training a ML Model (Light Gradient Boosting Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9f07c27-e5f5-4cdd-a6ad-95bd59b351b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\cw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\cw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\cw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\cw\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lightgbm) (2.1.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lightgbm) (1.14.1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, max_depth=6, verbose=-1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LGBMClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LGBMClassifier(class_weight=&#x27;balanced&#x27;, max_depth=6, verbose=-1)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(class_weight='balanced', max_depth=6, verbose=-1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!C:\\Users\\cw\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    num_leaves=31,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    verbose=-1,\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "lgb_model.fit(X_train_vec, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d6de207-5b3c-4816-93d6-5620db40c18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8153846153846154\n",
      "Weighted F1: 0.8175609324545495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "\n",
    "y_pred = lgb_model.predict(X_test_vec)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"weighted\")  # weighted → handles class imbalance\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"Weighted F1:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9472d18-a914-4da4-9d0b-28e326c9bd33",
   "metadata": {},
   "source": [
    "## Function with params as -> tf-idf feature, learning rate, number_of_iters, L1_lambda1, L2_lambda2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cbb55c9-76d9-45f8-83e4-549613077b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_and_test_simple_ml_model(tfidf_params, lr, n_iters, model_name, lambda_l1 = 0.1, lambda_l2=0.1):\n",
    "    c = 1/lr\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=tfidf_params)\n",
    "    X_train_vec = vectorizer.fit_transform(X_train)\n",
    "    X_test_vec = vectorizer.transform(X_test)\n",
    "    \n",
    "    scaler = StandardScaler(with_mean=False)  # TF-IDF is sparse\n",
    "    X_train_vec = scaler.fit_transform(X_train_vec)\n",
    "    X_test_vec = scaler.transform(X_test_vec)\n",
    "\n",
    "    \n",
    "    if model_name == 'lgb':\n",
    "        model = lgb.LGBMClassifier(\n",
    "            num_leaves=31,\n",
    "            max_depth=6,\n",
    "            learning_rate=lr,\n",
    "            n_estimators=100,\n",
    "            lambda_l1= lambda_l1,  \n",
    "            lambda_l2= lambda_l2,  \n",
    "            verbose=-1\n",
    "        )\n",
    "        model.fit(X_train_vec, y_train)\n",
    "\n",
    "    if model_name == 'logreg':\n",
    "        model = LogisticRegression(max_iter=n_iters, C=c, solver='saga')\n",
    "        model.fit(X_train_vec, y_train)\n",
    "\n",
    "    predsi = model.predict(X_test_vec)\n",
    "    train_predsi = model.predict(X_train_vec)\n",
    "\n",
    "    train_acc = accuracy_score(y_train, train_predsi)\n",
    "    train_f1 = f1_score(y_train, train_predsi, average=\"weighted\")\n",
    "    \n",
    "    acc = accuracy_score(y_test, predsi)\n",
    "    f1 = f1_score(y_test, predsi, average=\"weighted\")  # weighted → handles class imbalance\n",
    "    \n",
    "\n",
    "\n",
    "    print(f\"{model_name:<8} | {n_iters:<7} | {lr:<5} | {tfidf_params:<15} | \"\n",
    "      f\"Test Acc: {acc:.4f} | Test F1: {f1:.4f} | \"\n",
    "      f\"Train Acc: {train_acc:.4f} | Train F1: {train_f1:.4f}\")\n",
    "\n",
    "    return acc, f1, model, vectorizer, scaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4156d11-b1ea-43ef-a22b-498216f87a93",
   "metadata": {},
   "source": [
    "## Manual Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7bbcaba-a75f-456a-b170-05b3bee2e962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model    | n_iters | lr     | TF-IDF               | Test Acc   | Test F1    | Train Acc  | Train F1  \n",
      "--------------------------------------------------------------------------------------------------------------\n",
      "lgb      | 10      | 0.01  | 10              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9141 | Train F1: 0.9131\n",
      "logreg   | 10      | 0.01  | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 25      | 0.01  | 10              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9141 | Train F1: 0.9131\n",
      "logreg   | 25      | 0.01  | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 50      | 0.01  | 10              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9141 | Train F1: 0.9131\n",
      "logreg   | 50      | 0.01  | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 100     | 0.01  | 10              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9141 | Train F1: 0.9131\n",
      "logreg   | 100     | 0.01  | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 10      | 0.05  | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9414 | Train F1: 0.9417\n",
      "logreg   | 10      | 0.05  | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9414 | Train F1: 0.9417\n",
      "lgb      | 25      | 0.05  | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9414 | Train F1: 0.9417\n",
      "logreg   | 25      | 0.05  | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 50      | 0.05  | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9414 | Train F1: 0.9417\n",
      "logreg   | 50      | 0.05  | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 100     | 0.05  | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9414 | Train F1: 0.9417\n",
      "logreg   | 100     | 0.05  | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 10      | 0.1   | 10              | Test Acc: 0.8615 | Test F1: 0.8634 | Train Acc: 0.9414 | Train F1: 0.9419\n",
      "logreg   | 10      | 0.1   | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9375 | Train F1: 0.9377\n",
      "lgb      | 25      | 0.1   | 10              | Test Acc: 0.8615 | Test F1: 0.8634 | Train Acc: 0.9414 | Train F1: 0.9419\n",
      "logreg   | 25      | 0.1   | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 50      | 0.1   | 10              | Test Acc: 0.8615 | Test F1: 0.8634 | Train Acc: 0.9414 | Train F1: 0.9419\n",
      "logreg   | 50      | 0.1   | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 100     | 0.1   | 10              | Test Acc: 0.8615 | Test F1: 0.8634 | Train Acc: 0.9414 | Train F1: 0.9419\n",
      "logreg   | 100     | 0.1   | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 10      | 0.3   | 10              | Test Acc: 0.8462 | Test F1: 0.8469 | Train Acc: 0.9414 | Train F1: 0.9417\n",
      "logreg   | 10      | 0.3   | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 25      | 0.3   | 10              | Test Acc: 0.8462 | Test F1: 0.8469 | Train Acc: 0.9414 | Train F1: 0.9417\n",
      "logreg   | 25      | 0.3   | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 50      | 0.3   | 10              | Test Acc: 0.8462 | Test F1: 0.8469 | Train Acc: 0.9414 | Train F1: 0.9417\n",
      "logreg   | 50      | 0.3   | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 100     | 0.3   | 10              | Test Acc: 0.8462 | Test F1: 0.8469 | Train Acc: 0.9414 | Train F1: 0.9417\n",
      "logreg   | 100     | 0.3   | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 10      | 0.9   | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9414 | Train F1: 0.9417\n",
      "logreg   | 10      | 0.9   | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 25      | 0.9   | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9414 | Train F1: 0.9417\n",
      "logreg   | 25      | 0.9   | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 50      | 0.9   | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9414 | Train F1: 0.9417\n",
      "logreg   | 50      | 0.9   | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 100     | 0.9   | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9414 | Train F1: 0.9417\n",
      "logreg   | 100     | 0.9   | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 10      | 0.001 | 10              | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6953 | Train F1: 0.5875\n",
      "logreg   | 10      | 0.001 | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 25      | 0.001 | 10              | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6953 | Train F1: 0.5875\n",
      "logreg   | 25      | 0.001 | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 50      | 0.001 | 10              | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6953 | Train F1: 0.5875\n",
      "logreg   | 50      | 0.001 | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 100     | 0.001 | 10              | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6953 | Train F1: 0.5875\n",
      "logreg   | 100     | 0.001 | 10              | Test Acc: 0.8615 | Test F1: 0.8623 | Train Acc: 0.9297 | Train F1: 0.9299\n",
      "lgb      | 10      | 0.01  | 20              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9102 | Train F1: 0.9093\n",
      "logreg   | 10      | 0.01  | 20              | Test Acc: 0.8769 | Test F1: 0.8795 | Train Acc: 0.9609 | Train F1: 0.9611\n",
      "lgb      | 25      | 0.01  | 20              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9102 | Train F1: 0.9093\n",
      "logreg   | 25      | 0.01  | 20              | Test Acc: 0.8769 | Test F1: 0.8795 | Train Acc: 0.9609 | Train F1: 0.9611\n",
      "lgb      | 50      | 0.01  | 20              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9102 | Train F1: 0.9093\n",
      "logreg   | 50      | 0.01  | 20              | Test Acc: 0.8769 | Test F1: 0.8795 | Train Acc: 0.9609 | Train F1: 0.9611\n",
      "lgb      | 100     | 0.01  | 20              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9102 | Train F1: 0.9093\n",
      "logreg   | 100     | 0.01  | 20              | Test Acc: 0.8769 | Test F1: 0.8779 | Train Acc: 0.9609 | Train F1: 0.9610\n",
      "lgb      | 10      | 0.05  | 20              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9531 | Train F1: 0.9533\n",
      "logreg   | 10      | 0.05  | 20              | Test Acc: 0.8615 | Test F1: 0.8625 | Train Acc: 0.9609 | Train F1: 0.9612\n",
      "lgb      | 25      | 0.05  | 20              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9531 | Train F1: 0.9533\n",
      "logreg   | 25      | 0.05  | 20              | Test Acc: 0.8769 | Test F1: 0.8795 | Train Acc: 0.9609 | Train F1: 0.9611\n",
      "lgb      | 50      | 0.05  | 20              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9531 | Train F1: 0.9533\n",
      "logreg   | 50      | 0.05  | 20              | Test Acc: 0.8769 | Test F1: 0.8795 | Train Acc: 0.9609 | Train F1: 0.9611\n",
      "lgb      | 100     | 0.05  | 20              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9531 | Train F1: 0.9533\n",
      "logreg   | 100     | 0.05  | 20              | Test Acc: 0.8769 | Test F1: 0.8779 | Train Acc: 0.9609 | Train F1: 0.9610\n",
      "lgb      | 10      | 0.1   | 20              | Test Acc: 0.8769 | Test F1: 0.8778 | Train Acc: 0.9609 | Train F1: 0.9613\n",
      "logreg   | 10      | 0.1   | 20              | Test Acc: 0.8769 | Test F1: 0.8795 | Train Acc: 0.9609 | Train F1: 0.9611\n",
      "lgb      | 25      | 0.1   | 20              | Test Acc: 0.8769 | Test F1: 0.8778 | Train Acc: 0.9609 | Train F1: 0.9613\n",
      "logreg   | 25      | 0.1   | 20              | Test Acc: 0.8769 | Test F1: 0.8795 | Train Acc: 0.9609 | Train F1: 0.9611\n",
      "lgb      | 50      | 0.1   | 20              | Test Acc: 0.8769 | Test F1: 0.8778 | Train Acc: 0.9609 | Train F1: 0.9613\n",
      "logreg   | 50      | 0.1   | 20              | Test Acc: 0.8769 | Test F1: 0.8795 | Train Acc: 0.9609 | Train F1: 0.9611\n",
      "lgb      | 100     | 0.1   | 20              | Test Acc: 0.8769 | Test F1: 0.8778 | Train Acc: 0.9609 | Train F1: 0.9613\n",
      "logreg   | 100     | 0.1   | 20              | Test Acc: 0.8769 | Test F1: 0.8779 | Train Acc: 0.9609 | Train F1: 0.9610\n",
      "lgb      | 10      | 0.3   | 20              | Test Acc: 0.8769 | Test F1: 0.8778 | Train Acc: 0.9648 | Train F1: 0.9652\n",
      "logreg   | 10      | 0.3   | 20              | Test Acc: 0.8615 | Test F1: 0.8625 | Train Acc: 0.9609 | Train F1: 0.9612\n",
      "lgb      | 25      | 0.3   | 20              | Test Acc: 0.8769 | Test F1: 0.8778 | Train Acc: 0.9648 | Train F1: 0.9652\n",
      "logreg   | 25      | 0.3   | 20              | Test Acc: 0.8615 | Test F1: 0.8625 | Train Acc: 0.9609 | Train F1: 0.9612\n",
      "lgb      | 50      | 0.3   | 20              | Test Acc: 0.8769 | Test F1: 0.8778 | Train Acc: 0.9648 | Train F1: 0.9652\n",
      "logreg   | 50      | 0.3   | 20              | Test Acc: 0.8615 | Test F1: 0.8625 | Train Acc: 0.9609 | Train F1: 0.9612\n",
      "lgb      | 100     | 0.3   | 20              | Test Acc: 0.8769 | Test F1: 0.8778 | Train Acc: 0.9648 | Train F1: 0.9652\n",
      "logreg   | 100     | 0.3   | 20              | Test Acc: 0.8615 | Test F1: 0.8625 | Train Acc: 0.9609 | Train F1: 0.9612\n",
      "lgb      | 10      | 0.9   | 20              | Test Acc: 0.8923 | Test F1: 0.8945 | Train Acc: 0.9648 | Train F1: 0.9655\n",
      "logreg   | 10      | 0.9   | 20              | Test Acc: 0.8615 | Test F1: 0.8625 | Train Acc: 0.9609 | Train F1: 0.9612\n",
      "lgb      | 25      | 0.9   | 20              | Test Acc: 0.8923 | Test F1: 0.8945 | Train Acc: 0.9648 | Train F1: 0.9655\n",
      "logreg   | 25      | 0.9   | 20              | Test Acc: 0.8615 | Test F1: 0.8625 | Train Acc: 0.9609 | Train F1: 0.9612\n",
      "lgb      | 50      | 0.9   | 20              | Test Acc: 0.8923 | Test F1: 0.8945 | Train Acc: 0.9648 | Train F1: 0.9655\n",
      "logreg   | 50      | 0.9   | 20              | Test Acc: 0.8615 | Test F1: 0.8625 | Train Acc: 0.9609 | Train F1: 0.9612\n",
      "lgb      | 100     | 0.9   | 20              | Test Acc: 0.8923 | Test F1: 0.8945 | Train Acc: 0.9648 | Train F1: 0.9655\n",
      "logreg   | 100     | 0.9   | 20              | Test Acc: 0.8615 | Test F1: 0.8625 | Train Acc: 0.9609 | Train F1: 0.9612\n",
      "lgb      | 10      | 0.001 | 20              | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6953 | Train F1: 0.5875\n",
      "logreg   | 10      | 0.001 | 20              | Test Acc: 0.8769 | Test F1: 0.8795 | Train Acc: 0.9609 | Train F1: 0.9611\n",
      "lgb      | 25      | 0.001 | 20              | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6953 | Train F1: 0.5875\n",
      "logreg   | 25      | 0.001 | 20              | Test Acc: 0.8769 | Test F1: 0.8795 | Train Acc: 0.9609 | Train F1: 0.9611\n",
      "lgb      | 50      | 0.001 | 20              | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6953 | Train F1: 0.5875\n",
      "logreg   | 50      | 0.001 | 20              | Test Acc: 0.8769 | Test F1: 0.8795 | Train Acc: 0.9609 | Train F1: 0.9611\n",
      "lgb      | 100     | 0.001 | 20              | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6953 | Train F1: 0.5875\n",
      "logreg   | 100     | 0.001 | 20              | Test Acc: 0.8769 | Test F1: 0.8779 | Train Acc: 0.9609 | Train F1: 0.9610\n",
      "lgb      | 10      | 0.01  | 50              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9180 | Train F1: 0.9171\n",
      "logreg   | 10      | 0.01  | 50              | Test Acc: 0.9231 | Test F1: 0.9225 | Train Acc: 0.9922 | Train F1: 0.9922\n",
      "lgb      | 25      | 0.01  | 50              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9180 | Train F1: 0.9171\n",
      "logreg   | 25      | 0.01  | 50              | Test Acc: 0.9077 | Test F1: 0.9060 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 50      | 0.01  | 50              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9180 | Train F1: 0.9171\n",
      "logreg   | 50      | 0.01  | 50              | Test Acc: 0.9077 | Test F1: 0.9060 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 100     | 0.01  | 50              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9180 | Train F1: 0.9171\n",
      "logreg   | 100     | 0.01  | 50              | Test Acc: 0.9077 | Test F1: 0.9058 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 10      | 0.05  | 50              | Test Acc: 0.8462 | Test F1: 0.8486 | Train Acc: 0.9609 | Train F1: 0.9609\n",
      "logreg   | 10      | 0.05  | 50              | Test Acc: 0.9231 | Test F1: 0.9225 | Train Acc: 0.9922 | Train F1: 0.9922\n",
      "lgb      | 25      | 0.05  | 50              | Test Acc: 0.8462 | Test F1: 0.8486 | Train Acc: 0.9609 | Train F1: 0.9609\n",
      "logreg   | 25      | 0.05  | 50              | Test Acc: 0.9077 | Test F1: 0.9060 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 50      | 0.05  | 50              | Test Acc: 0.8462 | Test F1: 0.8486 | Train Acc: 0.9609 | Train F1: 0.9609\n",
      "logreg   | 50      | 0.05  | 50              | Test Acc: 0.9077 | Test F1: 0.9060 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 100     | 0.05  | 50              | Test Acc: 0.8462 | Test F1: 0.8486 | Train Acc: 0.9609 | Train F1: 0.9609\n",
      "logreg   | 100     | 0.05  | 50              | Test Acc: 0.9077 | Test F1: 0.9058 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 10      | 0.1   | 50              | Test Acc: 0.8154 | Test F1: 0.8188 | Train Acc: 0.9727 | Train F1: 0.9727\n",
      "logreg   | 10      | 0.1   | 50              | Test Acc: 0.9077 | Test F1: 0.9058 | Train Acc: 0.9922 | Train F1: 0.9922\n",
      "lgb      | 25      | 0.1   | 50              | Test Acc: 0.8154 | Test F1: 0.8188 | Train Acc: 0.9727 | Train F1: 0.9727\n",
      "logreg   | 25      | 0.1   | 50              | Test Acc: 0.9077 | Test F1: 0.9058 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 50      | 0.1   | 50              | Test Acc: 0.8154 | Test F1: 0.8188 | Train Acc: 0.9727 | Train F1: 0.9727\n",
      "logreg   | 50      | 0.1   | 50              | Test Acc: 0.9077 | Test F1: 0.9060 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 100     | 0.1   | 50              | Test Acc: 0.8154 | Test F1: 0.8188 | Train Acc: 0.9727 | Train F1: 0.9727\n",
      "logreg   | 100     | 0.1   | 50              | Test Acc: 0.9077 | Test F1: 0.9058 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 10      | 0.3   | 50              | Test Acc: 0.8462 | Test F1: 0.8483 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 10      | 0.3   | 50              | Test Acc: 0.9231 | Test F1: 0.9225 | Train Acc: 0.9922 | Train F1: 0.9922\n",
      "lgb      | 25      | 0.3   | 50              | Test Acc: 0.8462 | Test F1: 0.8483 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 25      | 0.3   | 50              | Test Acc: 0.9077 | Test F1: 0.9060 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 50      | 0.3   | 50              | Test Acc: 0.8462 | Test F1: 0.8483 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 50      | 0.3   | 50              | Test Acc: 0.9077 | Test F1: 0.9060 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 100     | 0.3   | 50              | Test Acc: 0.8462 | Test F1: 0.8483 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 100     | 0.3   | 50              | Test Acc: 0.9077 | Test F1: 0.9058 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 10      | 0.9   | 50              | Test Acc: 0.8462 | Test F1: 0.8483 | Train Acc: 0.9805 | Train F1: 0.9805\n",
      "logreg   | 10      | 0.9   | 50              | Test Acc: 0.9231 | Test F1: 0.9225 | Train Acc: 0.9922 | Train F1: 0.9922\n",
      "lgb      | 25      | 0.9   | 50              | Test Acc: 0.8462 | Test F1: 0.8483 | Train Acc: 0.9805 | Train F1: 0.9805\n",
      "logreg   | 25      | 0.9   | 50              | Test Acc: 0.9077 | Test F1: 0.9060 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 50      | 0.9   | 50              | Test Acc: 0.8462 | Test F1: 0.8483 | Train Acc: 0.9805 | Train F1: 0.9805\n",
      "logreg   | 50      | 0.9   | 50              | Test Acc: 0.9077 | Test F1: 0.9060 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 100     | 0.9   | 50              | Test Acc: 0.8462 | Test F1: 0.8483 | Train Acc: 0.9805 | Train F1: 0.9805\n",
      "logreg   | 100     | 0.9   | 50              | Test Acc: 0.9077 | Test F1: 0.9060 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 10      | 0.001 | 50              | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6992 | Train F1: 0.5908\n",
      "logreg   | 10      | 0.001 | 50              | Test Acc: 0.9231 | Test F1: 0.9225 | Train Acc: 0.9922 | Train F1: 0.9922\n",
      "lgb      | 25      | 0.001 | 50              | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6992 | Train F1: 0.5908\n",
      "logreg   | 25      | 0.001 | 50              | Test Acc: 0.9077 | Test F1: 0.9060 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 50      | 0.001 | 50              | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6992 | Train F1: 0.5908\n",
      "logreg   | 50      | 0.001 | 50              | Test Acc: 0.9231 | Test F1: 0.9225 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 100     | 0.001 | 50              | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6992 | Train F1: 0.5908\n",
      "logreg   | 100     | 0.001 | 50              | Test Acc: 0.9077 | Test F1: 0.9060 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 10      | 0.01  | 75              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9180 | Train F1: 0.9172\n",
      "logreg   | 10      | 0.01  | 75              | Test Acc: 0.9538 | Test F1: 0.9532 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.01  | 75              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9180 | Train F1: 0.9172\n",
      "logreg   | 25      | 0.01  | 75              | Test Acc: 0.9538 | Test F1: 0.9532 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.01  | 75              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9180 | Train F1: 0.9172\n",
      "logreg   | 50      | 0.01  | 75              | Test Acc: 0.9538 | Test F1: 0.9532 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.01  | 75              | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9180 | Train F1: 0.9172\n",
      "logreg   | 100     | 0.01  | 75              | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.05  | 75              | Test Acc: 0.8923 | Test F1: 0.8929 | Train Acc: 0.9570 | Train F1: 0.9569\n",
      "logreg   | 10      | 0.05  | 75              | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.05  | 75              | Test Acc: 0.8923 | Test F1: 0.8929 | Train Acc: 0.9570 | Train F1: 0.9569\n",
      "logreg   | 25      | 0.05  | 75              | Test Acc: 0.9538 | Test F1: 0.9534 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.05  | 75              | Test Acc: 0.8923 | Test F1: 0.8929 | Train Acc: 0.9570 | Train F1: 0.9569\n",
      "logreg   | 50      | 0.05  | 75              | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.05  | 75              | Test Acc: 0.8923 | Test F1: 0.8929 | Train Acc: 0.9570 | Train F1: 0.9569\n",
      "logreg   | 100     | 0.05  | 75              | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.1   | 75              | Test Acc: 0.8769 | Test F1: 0.8799 | Train Acc: 0.9688 | Train F1: 0.9689\n",
      "logreg   | 10      | 0.1   | 75              | Test Acc: 0.9538 | Test F1: 0.9532 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.1   | 75              | Test Acc: 0.8769 | Test F1: 0.8799 | Train Acc: 0.9688 | Train F1: 0.9689\n",
      "logreg   | 25      | 0.1   | 75              | Test Acc: 0.9538 | Test F1: 0.9532 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.1   | 75              | Test Acc: 0.8769 | Test F1: 0.8799 | Train Acc: 0.9688 | Train F1: 0.9689\n",
      "logreg   | 50      | 0.1   | 75              | Test Acc: 0.9538 | Test F1: 0.9534 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.1   | 75              | Test Acc: 0.8769 | Test F1: 0.8799 | Train Acc: 0.9688 | Train F1: 0.9689\n",
      "logreg   | 100     | 0.1   | 75              | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.3   | 75              | Test Acc: 0.8923 | Test F1: 0.8963 | Train Acc: 0.9688 | Train F1: 0.9689\n",
      "logreg   | 10      | 0.3   | 75              | Test Acc: 0.9538 | Test F1: 0.9534 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.3   | 75              | Test Acc: 0.8923 | Test F1: 0.8963 | Train Acc: 0.9688 | Train F1: 0.9689\n",
      "logreg   | 25      | 0.3   | 75              | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.3   | 75              | Test Acc: 0.8923 | Test F1: 0.8963 | Train Acc: 0.9688 | Train F1: 0.9689\n",
      "logreg   | 50      | 0.3   | 75              | Test Acc: 0.9538 | Test F1: 0.9534 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.3   | 75              | Test Acc: 0.8923 | Test F1: 0.8963 | Train Acc: 0.9688 | Train F1: 0.9689\n",
      "logreg   | 100     | 0.3   | 75              | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.9   | 75              | Test Acc: 0.8769 | Test F1: 0.8811 | Train Acc: 0.9766 | Train F1: 0.9767\n",
      "logreg   | 10      | 0.9   | 75              | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.9   | 75              | Test Acc: 0.8769 | Test F1: 0.8811 | Train Acc: 0.9766 | Train F1: 0.9767\n",
      "logreg   | 25      | 0.9   | 75              | Test Acc: 0.9385 | Test F1: 0.9374 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.9   | 75              | Test Acc: 0.8769 | Test F1: 0.8811 | Train Acc: 0.9766 | Train F1: 0.9767\n",
      "logreg   | 50      | 0.9   | 75              | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.9   | 75              | Test Acc: 0.8769 | Test F1: 0.8811 | Train Acc: 0.9766 | Train F1: 0.9767\n",
      "logreg   | 100     | 0.9   | 75              | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.001 | 75              | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6953 | Train F1: 0.5875\n",
      "logreg   | 10      | 0.001 | 75              | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.001 | 75              | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6953 | Train F1: 0.5875\n",
      "logreg   | 25      | 0.001 | 75              | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.001 | 75              | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6953 | Train F1: 0.5875\n",
      "logreg   | 50      | 0.001 | 75              | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.001 | 75              | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6953 | Train F1: 0.5875\n",
      "logreg   | 100     | 0.001 | 75              | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.01  | 100             | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9180 | Train F1: 0.9172\n",
      "logreg   | 10      | 0.01  | 100             | Test Acc: 0.9077 | Test F1: 0.9060 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 25      | 0.01  | 100             | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9180 | Train F1: 0.9172\n",
      "logreg   | 25      | 0.01  | 100             | Test Acc: 0.9231 | Test F1: 0.9215 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.01  | 100             | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9180 | Train F1: 0.9172\n",
      "logreg   | 50      | 0.01  | 100             | Test Acc: 0.9231 | Test F1: 0.9211 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.01  | 100             | Test Acc: 0.9077 | Test F1: 0.9081 | Train Acc: 0.9180 | Train F1: 0.9172\n",
      "logreg   | 100     | 0.01  | 100             | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.05  | 100             | Test Acc: 0.8769 | Test F1: 0.8782 | Train Acc: 0.9570 | Train F1: 0.9570\n",
      "logreg   | 10      | 0.05  | 100             | Test Acc: 0.9231 | Test F1: 0.9220 | Train Acc: 0.9922 | Train F1: 0.9922\n",
      "lgb      | 25      | 0.05  | 100             | Test Acc: 0.8769 | Test F1: 0.8782 | Train Acc: 0.9570 | Train F1: 0.9570\n",
      "logreg   | 25      | 0.05  | 100             | Test Acc: 0.9231 | Test F1: 0.9219 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 50      | 0.05  | 100             | Test Acc: 0.8769 | Test F1: 0.8782 | Train Acc: 0.9570 | Train F1: 0.9570\n",
      "logreg   | 50      | 0.05  | 100             | Test Acc: 0.9538 | Test F1: 0.9532 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.05  | 100             | Test Acc: 0.8769 | Test F1: 0.8782 | Train Acc: 0.9570 | Train F1: 0.9570\n",
      "logreg   | 100     | 0.05  | 100             | Test Acc: 0.9231 | Test F1: 0.9213 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.1   | 100             | Test Acc: 0.8923 | Test F1: 0.8928 | Train Acc: 0.9727 | Train F1: 0.9727\n",
      "logreg   | 10      | 0.1   | 100             | Test Acc: 0.9385 | Test F1: 0.9374 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.1   | 100             | Test Acc: 0.8923 | Test F1: 0.8928 | Train Acc: 0.9727 | Train F1: 0.9727\n",
      "logreg   | 25      | 0.1   | 100             | Test Acc: 0.9231 | Test F1: 0.9211 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.1   | 100             | Test Acc: 0.8923 | Test F1: 0.8928 | Train Acc: 0.9727 | Train F1: 0.9727\n",
      "logreg   | 50      | 0.1   | 100             | Test Acc: 0.9231 | Test F1: 0.9215 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.1   | 100             | Test Acc: 0.8923 | Test F1: 0.8928 | Train Acc: 0.9727 | Train F1: 0.9727\n",
      "logreg   | 100     | 0.1   | 100             | Test Acc: 0.9231 | Test F1: 0.9211 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.3   | 100             | Test Acc: 0.9077 | Test F1: 0.9092 | Train Acc: 0.9805 | Train F1: 0.9805\n",
      "logreg   | 10      | 0.3   | 100             | Test Acc: 0.9385 | Test F1: 0.9374 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 25      | 0.3   | 100             | Test Acc: 0.9077 | Test F1: 0.9092 | Train Acc: 0.9805 | Train F1: 0.9805\n",
      "logreg   | 25      | 0.3   | 100             | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.3   | 100             | Test Acc: 0.9077 | Test F1: 0.9092 | Train Acc: 0.9805 | Train F1: 0.9805\n",
      "logreg   | 50      | 0.3   | 100             | Test Acc: 0.9231 | Test F1: 0.9215 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.3   | 100             | Test Acc: 0.9077 | Test F1: 0.9092 | Train Acc: 0.9805 | Train F1: 0.9805\n",
      "logreg   | 100     | 0.3   | 100             | Test Acc: 0.9385 | Test F1: 0.9373 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.9   | 100             | Test Acc: 0.9077 | Test F1: 0.9092 | Train Acc: 0.9805 | Train F1: 0.9804\n",
      "logreg   | 10      | 0.9   | 100             | Test Acc: 0.9692 | Test F1: 0.9690 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 25      | 0.9   | 100             | Test Acc: 0.9077 | Test F1: 0.9092 | Train Acc: 0.9805 | Train F1: 0.9804\n",
      "logreg   | 25      | 0.9   | 100             | Test Acc: 0.9231 | Test F1: 0.9211 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.9   | 100             | Test Acc: 0.9077 | Test F1: 0.9092 | Train Acc: 0.9805 | Train F1: 0.9804\n",
      "logreg   | 50      | 0.9   | 100             | Test Acc: 0.9231 | Test F1: 0.9211 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.9   | 100             | Test Acc: 0.9077 | Test F1: 0.9092 | Train Acc: 0.9805 | Train F1: 0.9804\n",
      "logreg   | 100     | 0.9   | 100             | Test Acc: 0.9231 | Test F1: 0.9211 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.001 | 100             | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6953 | Train F1: 0.5875\n",
      "logreg   | 10      | 0.001 | 100             | Test Acc: 0.9538 | Test F1: 0.9538 | Train Acc: 0.9961 | Train F1: 0.9961\n",
      "lgb      | 25      | 0.001 | 100             | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6953 | Train F1: 0.5875\n",
      "logreg   | 25      | 0.001 | 100             | Test Acc: 0.9231 | Test F1: 0.9211 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.001 | 100             | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6953 | Train F1: 0.5875\n",
      "logreg   | 50      | 0.001 | 100             | Test Acc: 0.9231 | Test F1: 0.9211 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.001 | 100             | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6953 | Train F1: 0.5875\n",
      "logreg   | 100     | 0.001 | 100             | Test Acc: 0.9231 | Test F1: 0.9211 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.01  | 500             | Test Acc: 0.8769 | Test F1: 0.8762 | Train Acc: 0.9297 | Train F1: 0.9296\n",
      "logreg   | 10      | 0.01  | 500             | Test Acc: 0.9692 | Test F1: 0.9692 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.01  | 500             | Test Acc: 0.8769 | Test F1: 0.8762 | Train Acc: 0.9297 | Train F1: 0.9296\n",
      "logreg   | 25      | 0.01  | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.01  | 500             | Test Acc: 0.8769 | Test F1: 0.8762 | Train Acc: 0.9297 | Train F1: 0.9296\n",
      "logreg   | 50      | 0.01  | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.01  | 500             | Test Acc: 0.8769 | Test F1: 0.8762 | Train Acc: 0.9297 | Train F1: 0.9296\n",
      "logreg   | 100     | 0.01  | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.05  | 500             | Test Acc: 0.8923 | Test F1: 0.8922 | Train Acc: 0.9609 | Train F1: 0.9610\n",
      "logreg   | 10      | 0.05  | 500             | Test Acc: 0.9692 | Test F1: 0.9692 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.05  | 500             | Test Acc: 0.8923 | Test F1: 0.8922 | Train Acc: 0.9609 | Train F1: 0.9610\n",
      "logreg   | 25      | 0.05  | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.05  | 500             | Test Acc: 0.8923 | Test F1: 0.8922 | Train Acc: 0.9609 | Train F1: 0.9610\n",
      "logreg   | 50      | 0.05  | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.05  | 500             | Test Acc: 0.8923 | Test F1: 0.8922 | Train Acc: 0.9609 | Train F1: 0.9610\n",
      "logreg   | 100     | 0.05  | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.1   | 500             | Test Acc: 0.8615 | Test F1: 0.8620 | Train Acc: 0.9727 | Train F1: 0.9727\n",
      "logreg   | 10      | 0.1   | 500             | Test Acc: 1.0000 | Test F1: 1.0000 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.1   | 500             | Test Acc: 0.8615 | Test F1: 0.8620 | Train Acc: 0.9727 | Train F1: 0.9727\n",
      "logreg   | 25      | 0.1   | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.1   | 500             | Test Acc: 0.8615 | Test F1: 0.8620 | Train Acc: 0.9727 | Train F1: 0.9727\n",
      "logreg   | 50      | 0.1   | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.1   | 500             | Test Acc: 0.8615 | Test F1: 0.8620 | Train Acc: 0.9727 | Train F1: 0.9727\n",
      "logreg   | 100     | 0.1   | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.3   | 500             | Test Acc: 0.8615 | Test F1: 0.8614 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 10      | 0.3   | 500             | Test Acc: 0.9692 | Test F1: 0.9692 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.3   | 500             | Test Acc: 0.8615 | Test F1: 0.8614 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 25      | 0.3   | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.3   | 500             | Test Acc: 0.8615 | Test F1: 0.8614 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 50      | 0.3   | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.3   | 500             | Test Acc: 0.8615 | Test F1: 0.8614 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 100     | 0.3   | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.9   | 500             | Test Acc: 0.8769 | Test F1: 0.8776 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 10      | 0.9   | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.9   | 500             | Test Acc: 0.8769 | Test F1: 0.8776 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 25      | 0.9   | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.9   | 500             | Test Acc: 0.8769 | Test F1: 0.8776 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 50      | 0.9   | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.9   | 500             | Test Acc: 0.8769 | Test F1: 0.8776 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 100     | 0.9   | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.001 | 500             | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6992 | Train F1: 0.5922\n",
      "logreg   | 10      | 0.001 | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.001 | 500             | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6992 | Train F1: 0.5922\n",
      "logreg   | 25      | 0.001 | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.001 | 500             | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6992 | Train F1: 0.5922\n",
      "logreg   | 50      | 0.001 | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.001 | 500             | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6992 | Train F1: 0.5922\n",
      "logreg   | 100     | 0.001 | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.01  | 1000            | Test Acc: 0.8769 | Test F1: 0.8762 | Train Acc: 0.9297 | Train F1: 0.9296\n",
      "logreg   | 10      | 0.01  | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.01  | 1000            | Test Acc: 0.8769 | Test F1: 0.8762 | Train Acc: 0.9297 | Train F1: 0.9296\n",
      "logreg   | 25      | 0.01  | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.01  | 1000            | Test Acc: 0.8769 | Test F1: 0.8762 | Train Acc: 0.9297 | Train F1: 0.9296\n",
      "logreg   | 50      | 0.01  | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.01  | 1000            | Test Acc: 0.8769 | Test F1: 0.8762 | Train Acc: 0.9297 | Train F1: 0.9296\n",
      "logreg   | 100     | 0.01  | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.05  | 1000            | Test Acc: 0.8923 | Test F1: 0.8922 | Train Acc: 0.9609 | Train F1: 0.9610\n",
      "logreg   | 10      | 0.05  | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.05  | 1000            | Test Acc: 0.8923 | Test F1: 0.8922 | Train Acc: 0.9609 | Train F1: 0.9610\n",
      "logreg   | 25      | 0.05  | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.05  | 1000            | Test Acc: 0.8923 | Test F1: 0.8922 | Train Acc: 0.9609 | Train F1: 0.9610\n",
      "logreg   | 50      | 0.05  | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.05  | 1000            | Test Acc: 0.8923 | Test F1: 0.8922 | Train Acc: 0.9609 | Train F1: 0.9610\n",
      "logreg   | 100     | 0.05  | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.1   | 1000            | Test Acc: 0.8615 | Test F1: 0.8620 | Train Acc: 0.9727 | Train F1: 0.9727\n",
      "logreg   | 10      | 0.1   | 1000            | Test Acc: 0.9692 | Test F1: 0.9692 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.1   | 1000            | Test Acc: 0.8615 | Test F1: 0.8620 | Train Acc: 0.9727 | Train F1: 0.9727\n",
      "logreg   | 25      | 0.1   | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.1   | 1000            | Test Acc: 0.8615 | Test F1: 0.8620 | Train Acc: 0.9727 | Train F1: 0.9727\n",
      "logreg   | 50      | 0.1   | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.1   | 1000            | Test Acc: 0.8615 | Test F1: 0.8620 | Train Acc: 0.9727 | Train F1: 0.9727\n",
      "logreg   | 100     | 0.1   | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.3   | 1000            | Test Acc: 0.8615 | Test F1: 0.8614 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 10      | 0.3   | 1000            | Test Acc: 0.9692 | Test F1: 0.9692 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.3   | 1000            | Test Acc: 0.8615 | Test F1: 0.8614 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 25      | 0.3   | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.3   | 1000            | Test Acc: 0.8615 | Test F1: 0.8614 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 50      | 0.3   | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.3   | 1000            | Test Acc: 0.8615 | Test F1: 0.8614 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 100     | 0.3   | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.9   | 1000            | Test Acc: 0.8769 | Test F1: 0.8776 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 10      | 0.9   | 1000            | Test Acc: 0.9692 | Test F1: 0.9692 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.9   | 1000            | Test Acc: 0.8769 | Test F1: 0.8776 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 25      | 0.9   | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.9   | 1000            | Test Acc: 0.8769 | Test F1: 0.8776 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 50      | 0.9   | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.9   | 1000            | Test Acc: 0.8769 | Test F1: 0.8776 | Train Acc: 0.9766 | Train F1: 0.9766\n",
      "logreg   | 100     | 0.9   | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 10      | 0.001 | 1000            | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6992 | Train F1: 0.5922\n",
      "logreg   | 10      | 0.001 | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 25      | 0.001 | 1000            | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6992 | Train F1: 0.5922\n",
      "logreg   | 25      | 0.001 | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 50      | 0.001 | 1000            | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6992 | Train F1: 0.5922\n",
      "logreg   | 50      | 0.001 | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
      "lgb      | 100     | 0.001 | 1000            | Test Acc: 0.6615 | Test F1: 0.5671 | Train Acc: 0.6992 | Train F1: 0.5922\n",
      "logreg   | 100     | 0.001 | 1000            | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "tfidf_options = [10, 20, 50, 75, 100, 500, 1000]\n",
    "lr_options = [0.01, 0.05, 0.1, 0.3, 0.9, 0.001]\n",
    "n_iters_options = [10, 25, 50, 100]\n",
    "\n",
    "print(f\"{'Model':<8} | {'n_iters':<7} | {'lr':<6} | {'TF-IDF':<20} | {'Test Acc':<10} | {'Test F1':<10} | {'Train Acc':<10} | {'Train F1':<10}\")\n",
    "print(\"-\" * 110)\n",
    "\n",
    "max_f1 = 0;\n",
    "tfidfs = 0\n",
    "rate = 0 \n",
    "iters = 0\n",
    "model_name= None\n",
    "\n",
    "for tfidf_param in tfidf_options:\n",
    "    for lr in lr_options:\n",
    "        for n_iter in n_iters_options:\n",
    "            acc1, f11, m1, v1, s1 = train_and_test_simple_ml_model(tfidf_param, lr, n_iter, \"lgb\")\n",
    "            acc2, f12, m2, v2, s2 = train_and_test_simple_ml_model(tfidf_param, lr, n_iter, \"logreg\")\n",
    "            if(f11 > max_f1):\n",
    "                max_f1 = f11;\n",
    "                tfidfs = tfidf_param\n",
    "                rate = lr \n",
    "                iters = n_iter\n",
    "                model_name=\"lgb\"\n",
    "            if(f12 > max_f1):\n",
    "                max_f1 = f12;\n",
    "                tfidfs = tfidf_param\n",
    "                rate = lr \n",
    "                iters = n_iter\n",
    "                model_name=\"logreg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ec6cfa1-0dc2-4777-b321-533cc965108f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logreg   | 10      | 0.1   | 500             | Test Acc: 1.0000 | Test F1: 1.0000 | Train Acc: 1.0000 | Train F1: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Best Model -> \n",
    "acc, f1, m, v, s = train_and_test_simple_ml_model(tfidfs, rate, iters, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9a78c2-717d-4dec-9397-97ba428bde59",
   "metadata": {},
   "source": [
    "## I have decided to use logistic regression. Now i will export this using joblib, import the same in .py file and convert to API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c525e35c-8c77-41fe-85df-3cd7a82f9b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# After training inside your function:\n",
    "joblib.dump(m, \"model.pkl\")\n",
    "joblib.dump(v, \"tfidf_vectorizer.pkl\")\n",
    "joblib.dump(s, \"scaler.pkl\")\n",
    "\n",
    "print(\"Exported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f17149-bd15-4afd-940a-9b09849dc4bc",
   "metadata": {},
   "source": [
    "## Fine-Tune Transformer Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c9f8bc4-9e8b-4524-951f-efe6bb6afbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.1.1)\n",
      "Requirement already satisfied: transformers[torch] in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.56.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (0.35.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[torch]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[torch]) (0.5.3)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers[torch]) (1.10.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (6.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\cw\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\cw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\cw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\cw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: C:\\Users\\cw\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!C:\\Users\\cw\\AppData\\Local\\Programs\\Python\\Python312\\python.exe -m pip install --upgrade torch datasets \"transformers[torch]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e97d39a-6ae8-430d-81c9-3c6341025c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "train_ds = Dataset.from_dict({\"text\": X_train, \"label\": y_train})\n",
    "val_ds = Dataset.from_dict({\"text\": X_test, \"label\": y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f186478b-231f-4388-8f62-66c7b5aedc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████| 256/256 [00:00<00:00, 13466.55 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████| 65/65 [00:00<00:00, 8029.86 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=True, truncation=True)\n",
    "\n",
    "train_ds = train_ds.map(tokenize, batched=True)\n",
    "val_ds = val_ds.map(tokenize, batched=True)\n",
    "\n",
    "train_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1860eaad-e07c-4c83-a1e3-482a258471ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 00:51, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.026900</td>\n",
       "      <td>0.854997</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.624129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.667600</td>\n",
       "      <td>0.475436</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.922752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.352500</td>\n",
       "      <td>0.310623</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.922752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.205900</td>\n",
       "      <td>0.254464</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.922752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>0.242973</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>0.937821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=80, training_loss=0.482620844244957, metrics={'train_runtime': 52.9088, 'train_samples_per_second': 24.193, 'train_steps_per_second': 1.512, 'total_flos': 4636441635840.0, 'train_loss': 0.482620844244957, 'epoch': 5.0})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\", \n",
    "    num_labels=3\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",  \n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",   \n",
    "    logging_strategy=\"epoch\" \n",
    ")\n",
    "\n",
    "# Metrics function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1\": f1_score(labels, preds, average=\"weighted\")\n",
    "    }\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,  \n",
    "    eval_dataset=val_ds,   \n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Training\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d428d59-afb1-45db-ac3e-a738a1905555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I am very happy with this product!\n",
      "Prediction: positive\n",
      "\n",
      "Text: This is terrible, I hate it.\n",
      "Prediction: positive\n",
      "\n",
      "Text: It's okay, nothing special.\n",
      "Prediction: negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "texts = [\n",
    "    \"I am very happy with this product!\",\n",
    "    \"This is terrible, I hate it.\",\n",
    "    \"It's okay, nothing special.\"\n",
    "]\n",
    "\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "model.eval() \n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = logits.argmax(dim=-1)\n",
    "\n",
    "label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "pred_labels = [label_map[p.item()] for p in predictions]\n",
    "\n",
    "# Show results\n",
    "for text, pred in zip(texts, pred_labels):\n",
    "    print(f\"Text: {text}\\nPrediction: {pred}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a992a22e-8718-4233-9ebb-446914e2822f",
   "metadata": {},
   "source": [
    "## Why Did I Select Logistic Regression over Transformer model & LGBM?."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d566c3-27d2-41e9-ae04-a3df1e909697",
   "metadata": {},
   "source": [
    "#### First of all we have very less data, that is just ~2000 examples + too many duplicates. at the end we have ~330 examples\n",
    "#### Transformers are Data Hungry models, so to fine tune them we wld need a lot of energy + for such small datasets there is no need of High computational transformer model.\n",
    "#### Talking about LGBM, LGBM is boosting method and yes they perfom very good, but on such small datasets + sparse matrix [ tf-idf will create a matrix in which as it considers vocabualry of all documents, it will be 0 most of the time, hence here LGBM cant generalize easily\n",
    "#### Logistic Regression, Simple model and for small datasets Log Regression is ok and due to its linear nature(which acts as a regularizer) we can generalise bettter compared to other 2 in this case, and the metrics talk the same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ede18-e5d1-49de-bb6a-9bc046581a72",
   "metadata": {},
   "source": [
    "##### Metrics of my best ML model:->\n",
    "\n",
    "##### logreg   | 10      | 0.01  | 500             | Test Acc: 0.9846 | Test F1: 0.9846 | Train Acc: 1.0000 | Train F1: 1.0000\n",
    "\n",
    "##### Metrics of my transformer model ->\n",
    "\n",
    "##### Epoch  5\t Training Loss: 0.137200\t   ValidationLoss:  0.202737\t    Accuracy: 0.938462\t   F1:0.937821\t    \n",
    "\n",
    "### Comprasion between LGBM & LogReg was done in Grid-SearchCV, For Transformer and LogReg , apart from my reasoning, Seeing the metrics it is clear that Log Reg is performing better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d00f115-e3b8-4ffb-9f32-21c2b7fb1dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
